{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n",
      "/home/M2015eliu/.pyenv/versions/anaconda2-4.1.1/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec\n"
     ]
    }
   ],
   "source": [
    "from lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rrng:\n",
      "type of rrng: <class 'theano.tensor.var.TensorVariable'>\n",
      "Elemwise{Cast{float32}}.0\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/\"\n",
    "training=True # Set to false to load weights\n",
    "Syn_aug=False # it False faster but does slightly worse on Test dataset\n",
    "\n",
    "sls=LSTM(\"new.p\",load=False,training=True)\n",
    "\n",
    "train=pickle.load(open(data_path+\"stsallrmf.p\",\"rb\"))#[:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print training\n",
    "print Syn_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training\n",
      "Training\n",
      "(0.4023701, 0.78751606, 0.72936829403460934)\n",
      "Epoch 0\n",
      "Epoch  0 Update  40 Cost  0.0189751982689\n",
      "Epoch  0 Update  80 Cost  0.0146785704419\n",
      "Epoch  0 Update  120 Cost  0.0101166311651\n",
      "epoch took: 3.43885803223\n",
      "(0.39700806, 0.78804338, 0.72359953285551504)\n",
      "Epoch 1\n",
      "Epoch  1 Update  160 Cost  0.0168419759721\n",
      "Epoch  1 Update  200 Cost  0.0182765368372\n",
      "Epoch  1 Update  240 Cost  0.0167405307293\n",
      "Epoch  1 Update  280 Cost  0.0244437959045\n",
      "epoch took: 3.50400114059\n",
      "(0.39033028, 0.7937609, 0.73155017511920184)\n",
      "Epoch 2\n",
      "Epoch  2 Update  320 Cost  0.0196155104786\n",
      "Epoch  2 Update  360 Cost  0.0166579373181\n",
      "Epoch  2 Update  400 Cost  0.0162735059857\n",
      "Epoch  2 Update  440 Cost  0.0195430107415\n",
      "epoch took: 3.3590490818\n",
      "Pre-training done\n",
      "Training\n",
      "(0.38835564, 0.79644454, 0.73909491907248104)\n",
      "Epoch 0\n",
      "Epoch  0 Update  40 Cost  0.014237399213\n",
      "Epoch  0 Update  80 Cost  0.0138074876741\n",
      "Epoch  0 Update  120 Cost  0.00826140027493\n",
      "epoch took: 3.31145906448\n",
      "(0.39064136, 0.79419643, 0.73390664832800745)\n",
      "Epoch 1\n",
      "Epoch  1 Update  160 Cost  0.0189026109874\n",
      "Epoch  1 Update  200 Cost  0.0209123492241\n",
      "Epoch  1 Update  240 Cost  0.0131260911003\n",
      "Epoch  1 Update  280 Cost  0.0142633561045\n",
      "epoch took: 3.33004593849\n",
      "(0.38918796, 0.79524153, 0.73486003758776164)\n",
      "Epoch 2\n",
      "Epoch  2 Update  320 Cost  0.0120970923454\n",
      "Epoch  2 Update  360 Cost  0.0181430727243\n",
      "Epoch  2 Update  400 Cost  0.0154971145093\n",
      "Epoch  2 Update  440 Cost  0.0229143835604\n",
      "epoch took: 3.40106606483\n",
      "(0.39073655, 0.79580134, 0.738658258057313)\n",
      "Epoch 3\n",
      "Epoch  3 Update  480 Cost  0.0136929852888\n",
      "Epoch  3 Update  520 Cost  0.0127538358793\n",
      "Epoch  3 Update  560 Cost  0.0123129952699\n",
      "Epoch  3 Update  600 Cost  0.0116542465985\n",
      "epoch took: 3.33135581017\n",
      "(0.38835964, 0.79546446, 0.733033400630698)\n",
      "Epoch 4\n",
      "Epoch  4 Update  640 Cost  0.0108208926395\n",
      "Epoch  4 Update  680 Cost  0.0136714912951\n",
      "Epoch  4 Update  720 Cost  0.0164288952947\n",
      "Epoch  4 Update  760 Cost  0.0168968699872\n",
      "epoch took: 3.33134007454\n",
      "(0.38668653, 0.79617816, 0.73076248602483218)\n",
      "Epoch 5\n",
      "Epoch  5 Update  800 Cost  0.012346547097\n",
      "Epoch  5 Update  840 Cost  0.0175439268351\n",
      "Epoch  5 Update  880 Cost  0.0137911401689\n",
      "Epoch  5 Update  920 Cost  0.0149360233918\n",
      "epoch took: 3.35432291031\n",
      "(0.38677162, 0.79636288, 0.73603892045324359)\n",
      "Epoch 6\n",
      "Epoch  6 Update  960 Cost  0.0170705467463\n",
      "Epoch  6 Update  1000 Cost  0.0186451915652\n",
      "Epoch  6 Update  1040 Cost  0.0132994232699\n",
      "Epoch  6 Update  1080 Cost  0.0153333088383\n",
      "epoch took: 3.33802986145\n",
      "(0.38728848, 0.79766446, 0.73614606278716233)\n",
      "Epoch 7\n",
      "Epoch  7 Update  1120 Cost  0.0179012063891\n",
      "Epoch  7 Update  1160 Cost  0.019797232002\n",
      "Epoch  7 Update  1200 Cost  0.0167776755989\n",
      "Epoch  7 Update  1240 Cost  0.0148288533092\n",
      "epoch took: 3.40920805931\n",
      "(0.3926453, 0.7909531, 0.72559915606478798)\n",
      "Epoch 8\n",
      "Epoch  8 Update  1280 Cost  0.0182625353336\n",
      "Epoch  8 Update  1320 Cost  0.0206630248576\n",
      "Epoch  8 Update  1360 Cost  0.00840427726507\n",
      "Epoch  8 Update  1400 Cost  0.0134162222967\n",
      "epoch took: 3.33725905418\n",
      "(0.38289452, 0.79963887, 0.73772118537012465)\n",
      "Epoch 9\n",
      "Epoch  9 Update  1440 Cost  0.0120780561119\n",
      "Epoch  9 Update  1480 Cost  0.0126078054309\n",
      "Epoch  9 Update  1520 Cost  0.0123010408133\n",
      "Epoch  9 Update  1560 Cost  0.0127580007538\n",
      "epoch took: 3.33082795143\n",
      "(0.38306758, 0.79872489, 0.73465577824681427)\n",
      "[ 0.4804768]\n"
     ]
    }
   ],
   "source": [
    "if training==True:\n",
    "    print \"Pre-training\"\n",
    "    sls.train_lstm(train,3) #66\n",
    "    print \"Pre-training done\"\n",
    "    train=pickle.load(open(data_path+\"semtrain.p\",'rb'))\n",
    "    if Syn_aug==True:\n",
    "        print \"expanding the training data\"\n",
    "        train=expand(train)\n",
    "        sls.train_lstm(train,10) # 340\n",
    "    else:\n",
    "        sls.train_lstm(train,10) # 330\n",
    "\n",
    "test=pickle.load(open(data_path+\"semtest.p\",'rb'))\n",
    "print sls.chkterr2(test)\n",
    "#Example\n",
    "sa=\"A truly wise man\"\n",
    "sb=\"He is smart\"\n",
    "print sls.predict_similarity(sa,sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = sls.tnewp['1lstm1_U'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray([[-0.03993093 -0.0295224   0.04586948 ..., -0.04820409 -0.02682941\n",
       "   0.00068803]\n",
       " [-0.04057835  0.02422544 -0.04633589 ..., -0.00731926 -0.07963052\n",
       "   0.03629887]\n",
       " [ 0.01725097  0.06457724  0.01996739 ..., -0.03807424 -0.0326746\n",
       "   0.06715687]\n",
       " ..., \n",
       " [ 0.0306936   0.02715957 -0.02817764 ...,  0.06217218  0.06979305\n",
       "   0.00169515]\n",
       " [ 0.04562829 -0.01621062 -0.0600726  ...,  0.05635365 -0.01515166\n",
       "   0.03488232]\n",
       " [-0.03464783 -0.05916307  0.01921439 ..., -0.00664429 -0.09820729\n",
       "   0.01949933]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03993093, -0.0295224 ,  0.04586948, ..., -0.04820409,\n",
       "        -0.02682941,  0.00068803],\n",
       "       [-0.04057835,  0.02422544, -0.04633589, ..., -0.00731926,\n",
       "        -0.07963052,  0.03629887],\n",
       "       [ 0.01725097,  0.06457724,  0.01996739, ..., -0.03807424,\n",
       "        -0.0326746 ,  0.06715687],\n",
       "       ..., \n",
       "       [ 0.0306936 ,  0.02715957, -0.02817764, ...,  0.06217218,\n",
       "         0.06979305,  0.00169515],\n",
       "       [ 0.04562829, -0.01621062, -0.0600726 , ...,  0.05635365,\n",
       "        -0.01515166,  0.03488232],\n",
       "       [-0.03464783, -0.05916307,  0.01921439, ..., -0.00664429,\n",
       "        -0.09820729,  0.01949933]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_params = unzip(sls.tnewp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('1lstm1_U',\n",
       "              array([[-0.03993093, -0.0295224 ,  0.04586948, ..., -0.04820409,\n",
       "                      -0.02682941,  0.00068803],\n",
       "                     [-0.04057835,  0.02422544, -0.04633589, ..., -0.00731926,\n",
       "                      -0.07963052,  0.03629887],\n",
       "                     [ 0.01725097,  0.06457724,  0.01996739, ..., -0.03807424,\n",
       "                      -0.0326746 ,  0.06715687],\n",
       "                     ..., \n",
       "                     [ 0.0306936 ,  0.02715957, -0.02817764, ...,  0.06217218,\n",
       "                       0.06979305,  0.00169515],\n",
       "                     [ 0.04562829, -0.01621062, -0.0600726 , ...,  0.05635365,\n",
       "                      -0.01515166,  0.03488232],\n",
       "                     [-0.03464783, -0.05916307,  0.01921439, ..., -0.00664429,\n",
       "                      -0.09820729,  0.01949933]], dtype=float32)),\n",
       "             ('1lstm1_W',\n",
       "              array([[ 0.02178388, -0.00493273,  0.03656084, ...,  0.01191543,\n",
       "                      -0.01061674, -0.00123528],\n",
       "                     [ 0.00948319, -0.02162605, -0.0064755 , ...,  0.01139504,\n",
       "                       0.0117857 ,  0.01428535],\n",
       "                     [-0.01578011,  0.02707235, -0.02549334, ..., -0.02715595,\n",
       "                       0.03249325,  0.01253573],\n",
       "                     ..., \n",
       "                     [-0.00520461,  0.01171297,  0.01332667, ..., -0.00728611,\n",
       "                      -0.03133005, -0.01807561],\n",
       "                     [-0.01676526, -0.0089975 , -0.00887926, ..., -0.00318049,\n",
       "                       0.02237732, -0.00917959],\n",
       "                     [ 0.01919708,  0.02837656,  0.03745101, ...,  0.01175958,\n",
       "                      -0.00171653, -0.01310578]], dtype=float32)),\n",
       "             ('1lstm1_b',\n",
       "              array([-0.13992016,  0.20304863,  0.20974894,  0.20679882,  0.24584614,\n",
       "                      0.47527921,  0.20766358, -0.12645534, -0.48385218, -0.11732766,\n",
       "                      0.44312531,  0.22937107,  0.15169935, -0.50635028, -0.22446904,\n",
       "                     -0.09759551,  0.12487718,  0.28450716,  0.2232673 ,  0.28337398,\n",
       "                      0.11553687, -0.07939079,  0.17058109,  0.26407805, -0.15077376,\n",
       "                     -0.38925654,  0.32219833, -0.24016708, -0.10033279, -0.15153141,\n",
       "                     -0.1270352 , -0.03962325, -0.40893704,  0.40497631,  0.48860273,\n",
       "                     -0.24609287,  0.33118474, -0.00540886,  0.32730541,  0.01547072,\n",
       "                      0.15554102,  0.06042892,  0.51524907,  0.42206058, -0.01675848,\n",
       "                     -0.48615107,  0.49573907,  0.02002442,  0.54634053,  0.34950301,\n",
       "                      1.52869236,  1.51094294,  1.51505733,  1.50728679,  1.5218904 ,\n",
       "                      1.51083541,  1.49711907,  1.5219996 ,  1.49381399,  1.51646185,\n",
       "                      1.519943  ,  1.51118374,  1.51414013,  1.50743389,  1.48345435,\n",
       "                      1.51297081,  1.51175439,  1.52605999,  1.52066529,  1.51303172,\n",
       "                      1.51647246,  1.51559794,  1.53877568,  1.51252127,  1.51558721,\n",
       "                      1.48520577,  1.51583707,  1.50790977,  1.52480066,  1.48744047,\n",
       "                      1.52108204,  1.48187792,  1.48330724,  1.51056707,  1.50838363,\n",
       "                      1.52582037,  1.51120067,  1.527722  ,  1.50976062,  1.5159992 ,\n",
       "                      1.51163876,  1.51337087,  1.50698793,  1.51343703,  1.53523362,\n",
       "                      1.49420273,  1.52738988,  1.5379678 ,  1.51743996,  1.51234961,\n",
       "                      0.13394038, -0.5079093 ,  0.08086479, -0.5123741 ,  0.19263971,\n",
       "                     -0.11222155,  0.07795934, -0.15450025, -0.39088148, -0.56061572,\n",
       "                      0.29203823, -0.41190949,  0.25706008,  0.43922225, -0.30779931,\n",
       "                      0.0062869 , -0.31938148,  0.42778862,  0.18186568, -0.28118724,\n",
       "                     -0.38127959, -0.31345907, -0.10924473, -0.34256592,  0.07919759,\n",
       "                     -0.0529489 ,  0.08287285, -0.66714793, -0.01682162,  0.40092295,\n",
       "                     -0.20642987,  0.39082602, -0.06201488, -0.25010684, -0.12293846,\n",
       "                     -0.04173776, -0.34160316,  0.44465017, -0.34508142, -0.44581029,\n",
       "                     -0.44803214, -0.40369576, -0.53830153, -0.04787579,  0.39256048,\n",
       "                     -0.47482252, -0.49299398,  0.39908499,  0.32512194, -0.25442484,\n",
       "                     -0.66524285, -0.45146391,  0.56983382, -0.38278589, -0.39429599,\n",
       "                     -0.44827664, -0.11799826, -0.58567423, -0.10508886, -0.54921311,\n",
       "                      0.49874744,  0.42380118, -0.09807232, -0.09765033, -0.10429786,\n",
       "                      0.52235198, -0.53742677,  0.57966578,  0.55919939, -0.41769913,\n",
       "                      0.48119792, -0.50261056, -0.01618996,  0.4145411 ,  0.58394647,\n",
       "                      0.13532309,  0.57747549,  0.4921414 , -0.57773483, -0.02324424,\n",
       "                     -0.5947026 ,  0.00421665, -0.14327994, -0.36430594, -0.44840285,\n",
       "                     -0.06746615, -0.43373773,  0.45621356, -0.52549189, -0.54744184,\n",
       "                     -0.45317218,  0.02186612,  0.41757077,  0.40424374, -0.5662623 ,\n",
       "                     -0.19092371,  0.01819867, -0.58187181, -0.49039313,  0.40177459], dtype=float32)),\n",
       "             ('2lstm1_U',\n",
       "              array([[-0.03993093, -0.0295224 ,  0.04586948, ..., -0.04820409,\n",
       "                      -0.02682941,  0.00068803],\n",
       "                     [-0.04057835,  0.02422544, -0.04633589, ..., -0.00731926,\n",
       "                      -0.07963052,  0.03629887],\n",
       "                     [ 0.01725097,  0.06457724,  0.01996739, ..., -0.03807424,\n",
       "                      -0.0326746 ,  0.06715687],\n",
       "                     ..., \n",
       "                     [ 0.0306936 ,  0.02715957, -0.02817764, ...,  0.06217218,\n",
       "                       0.06979305,  0.00169515],\n",
       "                     [ 0.04562829, -0.01621062, -0.0600726 , ...,  0.05635365,\n",
       "                      -0.01515166,  0.03488232],\n",
       "                     [-0.03464783, -0.05916307,  0.01921439, ..., -0.00664429,\n",
       "                      -0.09820729,  0.01949933]], dtype=float32)),\n",
       "             ('2lstm1_W',\n",
       "              array([[ 0.02178388, -0.00493273,  0.03656084, ...,  0.01191543,\n",
       "                      -0.01061674, -0.00123528],\n",
       "                     [ 0.00948319, -0.02162605, -0.0064755 , ...,  0.01139504,\n",
       "                       0.0117857 ,  0.01428535],\n",
       "                     [-0.01578011,  0.02707235, -0.02549334, ..., -0.02715595,\n",
       "                       0.03249325,  0.01253573],\n",
       "                     ..., \n",
       "                     [-0.00520461,  0.01171297,  0.01332667, ..., -0.00728611,\n",
       "                      -0.03133005, -0.01807561],\n",
       "                     [-0.01676526, -0.0089975 , -0.00887926, ..., -0.00318049,\n",
       "                       0.02237732, -0.00917959],\n",
       "                     [ 0.01919708,  0.02837656,  0.03745101, ...,  0.01175958,\n",
       "                      -0.00171653, -0.01310578]], dtype=float32)),\n",
       "             ('2lstm1_b',\n",
       "              array([-0.13992016,  0.20304863,  0.20974894,  0.20679882,  0.24584614,\n",
       "                      0.47527921,  0.20766358, -0.12645534, -0.48385218, -0.11732766,\n",
       "                      0.44312531,  0.22937107,  0.15169935, -0.50635028, -0.22446904,\n",
       "                     -0.09759551,  0.12487718,  0.28450716,  0.2232673 ,  0.28337398,\n",
       "                      0.11553687, -0.07939079,  0.17058109,  0.26407805, -0.15077376,\n",
       "                     -0.38925654,  0.32219833, -0.24016708, -0.10033279, -0.15153141,\n",
       "                     -0.1270352 , -0.03962325, -0.40893704,  0.40497631,  0.48860273,\n",
       "                     -0.24609287,  0.33118474, -0.00540886,  0.32730541,  0.01547072,\n",
       "                      0.15554102,  0.06042892,  0.51524907,  0.42206058, -0.01675848,\n",
       "                     -0.48615107,  0.49573907,  0.02002442,  0.54634053,  0.34950301,\n",
       "                      1.52869236,  1.51094294,  1.51505733,  1.50728679,  1.5218904 ,\n",
       "                      1.51083541,  1.49711907,  1.5219996 ,  1.49381399,  1.51646185,\n",
       "                      1.519943  ,  1.51118374,  1.51414013,  1.50743389,  1.48345435,\n",
       "                      1.51297081,  1.51175439,  1.52605999,  1.52066529,  1.51303172,\n",
       "                      1.51647246,  1.51559794,  1.53877568,  1.51252127,  1.51558721,\n",
       "                      1.48520577,  1.51583707,  1.50790977,  1.52480066,  1.48744047,\n",
       "                      1.52108204,  1.48187792,  1.48330724,  1.51056707,  1.50838363,\n",
       "                      1.52582037,  1.51120067,  1.527722  ,  1.50976062,  1.5159992 ,\n",
       "                      1.51163876,  1.51337087,  1.50698793,  1.51343703,  1.53523362,\n",
       "                      1.49420273,  1.52738988,  1.5379678 ,  1.51743996,  1.51234961,\n",
       "                      0.13394038, -0.5079093 ,  0.08086479, -0.5123741 ,  0.19263971,\n",
       "                     -0.11222155,  0.07795934, -0.15450025, -0.39088148, -0.56061572,\n",
       "                      0.29203823, -0.41190949,  0.25706008,  0.43922225, -0.30779931,\n",
       "                      0.0062869 , -0.31938148,  0.42778862,  0.18186568, -0.28118724,\n",
       "                     -0.38127959, -0.31345907, -0.10924473, -0.34256592,  0.07919759,\n",
       "                     -0.0529489 ,  0.08287285, -0.66714793, -0.01682162,  0.40092295,\n",
       "                     -0.20642987,  0.39082602, -0.06201488, -0.25010684, -0.12293846,\n",
       "                     -0.04173776, -0.34160316,  0.44465017, -0.34508142, -0.44581029,\n",
       "                     -0.44803214, -0.40369576, -0.53830153, -0.04787579,  0.39256048,\n",
       "                     -0.47482252, -0.49299398,  0.39908499,  0.32512194, -0.25442484,\n",
       "                     -0.66524285, -0.45146391,  0.56983382, -0.38278589, -0.39429599,\n",
       "                     -0.44827664, -0.11799826, -0.58567423, -0.10508886, -0.54921311,\n",
       "                      0.49874744,  0.42380118, -0.09807232, -0.09765033, -0.10429786,\n",
       "                      0.52235198, -0.53742677,  0.57966578,  0.55919939, -0.41769913,\n",
       "                      0.48119792, -0.50261056, -0.01618996,  0.4145411 ,  0.58394647,\n",
       "                      0.13532309,  0.57747549,  0.4921414 , -0.57773483, -0.02324424,\n",
       "                     -0.5947026 ,  0.00421665, -0.14327994, -0.36430594, -0.44840285,\n",
       "                     -0.06746615, -0.43373773,  0.45621356, -0.52549189, -0.54744184,\n",
       "                     -0.45317218,  0.02186612,  0.41757077,  0.40424374, -0.5662623 ,\n",
       "                     -0.19092371,  0.01819867, -0.58187181, -0.49039313,  0.40177459], dtype=float32))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('11151656.p', 'wb') as handle:\n",
    "    pickle.dump(new_params, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4804768]\n"
     ]
    }
   ],
   "source": [
    "ls=LSTM(\"11151656.p\",load=True,training=False)\n",
    "# test=pickle.load(open(\"semtest.p\",'rb'))\n",
    "sa=\"A truly wise man\"\n",
    "sb=\"He is smart\"\n",
    "print ls.predict_similarity(sa,sb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n",
      "/home/M2015eliu/.pyenv/versions/anaconda2-4.1.1/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec\n",
      "Pre-training\n",
      "Training\n",
      "(1.9455892, 0.33838001, 0.31235108672140455)\n",
      "Epoch 0\n",
      "Epoch  0 Update  40 Cost  0.129388704896\n",
      "Epoch  0 Update  80 Cost  0.0819042176008\n",
      "Epoch  0 Update  120 Cost  0.0702883079648\n",
      "Epoch  0 Update  160 Cost  0.0975988805294\n",
      "Epoch  0 Update  200 Cost  0.0889935418963\n",
      "Epoch  0 Update  240 Cost  0.0655747801065\n",
      "Epoch  0 Update  280 Cost  0.0707493275404\n",
      "Epoch  0 Update  320 Cost  0.057680144906\n",
      "epoch took: 11.9701330662\n",
      "(0.76572013, 0.5547443, 0.53833978242243419)\n",
      "Epoch 1\n",
      "Epoch  1 Update  360 Cost  0.0679180771112\n",
      "Epoch  1 Update  400 Cost  0.046746045351\n",
      "Epoch  1 Update  440 Cost  0.0616952739656\n",
      "Epoch  1 Update  480 Cost  0.078190498054\n",
      "Epoch  1 Update  520 Cost  0.0366325825453\n",
      "Epoch  1 Update  560 Cost  0.0529292747378\n",
      "Epoch  1 Update  600 Cost  0.0637622475624\n",
      "Epoch  1 Update  640 Cost  0.0520761534572\n",
      "Epoch  1 Update  680 Cost  0.0587894693017\n",
      "epoch took: 11.8092110157\n",
      "(0.68554372, 0.60262203, 0.58205709665509464)\n",
      "Epoch 2\n",
      "Epoch  2 Update  720 Cost  0.0420302674174\n",
      "Epoch  2 Update  760 Cost  0.0677881985903\n",
      "Epoch  2 Update  800 Cost  0.0574387125671\n",
      "Epoch  2 Update  840 Cost  0.0597691312432\n",
      "Epoch  2 Update  880 Cost  0.0580240115523\n",
      "Epoch  2 Update  920 Cost  0.0700484067202\n",
      "Epoch  2 Update  960 Cost  0.0469438284636\n",
      "Epoch  2 Update  1000 Cost  0.0357566028833\n",
      "Epoch  2 Update  1040 Cost  0.0535696856678\n",
      "epoch took: 11.900949955\n",
      "Pre-training done\n",
      "Training\n",
      "(0.70141381, 0.60126942, 0.58232779356681241)\n",
      "Epoch 0\n",
      "Epoch  0 Update  40 Cost  0.0408712029457\n",
      "Epoch  0 Update  80 Cost  0.0517862923443\n",
      "Epoch  0 Update  120 Cost  0.0275667291135\n",
      "epoch took: 3.33157396317\n",
      "(0.51896292, 0.70296329, 0.65765148527576556)\n",
      "Epoch 1\n",
      "Epoch  1 Update  160 Cost  0.0308981239796\n",
      "Epoch  1 Update  200 Cost  0.0305912420154\n",
      "Epoch  1 Update  240 Cost  0.0328226014972\n",
      "Epoch  1 Update  280 Cost  0.0330070368946\n",
      "epoch took: 3.33364319801\n",
      "(0.46785083, 0.74165392, 0.68910820963129971)\n",
      "Epoch 2\n",
      "Epoch  2 Update  320 Cost  0.0233561210334\n",
      "Epoch  2 Update  360 Cost  0.0257504098117\n",
      "Epoch  2 Update  400 Cost  0.0252582896501\n",
      "Epoch  2 Update  440 Cost  0.0197800993919\n",
      "epoch took: 3.31938505173\n",
      "(0.45444757, 0.7510699, 0.69465696799961707)\n",
      "Epoch 3\n",
      "Epoch  3 Update  480 Cost  0.0221062768251\n",
      "Epoch  3 Update  520 Cost  0.0282895937562\n",
      "Epoch  3 Update  560 Cost  0.0200900696218\n",
      "Epoch  3 Update  600 Cost  0.0160696357489\n",
      "epoch took: 3.32097196579\n",
      "(0.4444176, 0.75805092, 0.69907403089844566)\n",
      "Epoch 4\n",
      "Epoch  4 Update  640 Cost  0.0248342528939\n",
      "Epoch  4 Update  680 Cost  0.0331332869828\n",
      "Epoch  4 Update  720 Cost  0.0160664450377\n",
      "Epoch  4 Update  760 Cost  0.0232188813388\n",
      "epoch took: 3.32993793488\n",
      "(0.43199775, 0.76743877, 0.71334380047639856)\n",
      "Epoch 5\n",
      "Epoch  5 Update  800 Cost  0.0216395743191\n",
      "Epoch  5 Update  840 Cost  0.027357339859\n",
      "Epoch  5 Update  880 Cost  0.0151617350057\n",
      "Epoch  5 Update  920 Cost  0.0181704834104\n",
      "epoch took: 3.31111693382\n",
      "(0.42151475, 0.77528238, 0.72163304056981759)\n",
      "Epoch 6\n",
      "Epoch  6 Update  960 Cost  0.0178941190243\n",
      "Epoch  6 Update  1000 Cost  0.0157476253808\n",
      "Epoch  6 Update  1040 Cost  0.0202586445957\n",
      "Epoch  6 Update  1080 Cost  0.0279444530606\n",
      "epoch took: 3.33876490593\n",
      "(0.40649012, 0.78217584, 0.72002964699957139)\n",
      "Epoch 7\n",
      "Epoch  7 Update  1120 Cost  0.0170990396291\n",
      "Epoch  7 Update  1160 Cost  0.0258700251579\n",
      "Epoch  7 Update  1200 Cost  0.019992634654\n",
      "Epoch  7 Update  1240 Cost  0.0158633645624\n",
      "epoch took: 3.33937311172\n",
      "(0.40985611, 0.78240091, 0.72053110929214492)\n",
      "Epoch 8\n",
      "Epoch  8 Update  1280 Cost  0.0197295993567\n",
      "Epoch  8 Update  1320 Cost  0.0147989224643\n",
      "Epoch  8 Update  1360 Cost  0.0136671289802\n",
      "Epoch  8 Update  1400 Cost  0.0182262416929\n",
      "epoch took: 3.32144117355\n",
      "(0.3989436, 0.78985947, 0.73209015720539239)\n",
      "Epoch 9\n",
      "Epoch  9 Update  1440 Cost  0.0135129066184\n",
      "Epoch  9 Update  1480 Cost  0.0209325812757\n",
      "Epoch  9 Update  1520 Cost  0.0152116371319\n",
      "Epoch  9 Update  1560 Cost  0.0238361023366\n",
      "epoch took: 3.3168489933\n",
      "(0.41117665, 0.78244752, 0.72481296465491307)\n",
      "[ 0.4911522]\n",
      "saving the model...\n"
     ]
    }
   ],
   "source": [
    "from lstm import *\n",
    "data_path = \"./data/\"\n",
    "training=True # Set to false to load weights\n",
    "Syn_aug=True # it False faster but does slightly worse on Test dataset\n",
    "sls=LSTM(data_path+\"11151521.p\",load=False,training=True)\n",
    "train=pickle.load(open(data_path+\"stsallrmf.p\",\"rb\"))#[:-8]\n",
    "if training==True:\n",
    "    print \"Pre-training\"\n",
    "    sls.train_lstm(train,3) #66\n",
    "    print \"Pre-training done\"\n",
    "    train=pickle.load(open(data_path+\"semtrain.p\",'rb'))\n",
    "    if Syn_aug==True:\n",
    "        print \"expanding the training data\"\n",
    "        train=expand(train)\n",
    "        sls.train_lstm(train,10) # 340\n",
    "    else:\n",
    "        sls.train_lstm(train,10) # 330\n",
    "\n",
    "print sls.chkterr2(test)\n",
    "#Example\n",
    "sa=\"A truly wise man\"\n",
    "sb=\"He is smart\"\n",
    "print sls.predict_similarity(sa,sb)\n",
    "\n",
    "sls.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4911522]\n"
     ]
    }
   ],
   "source": [
    "ls=LSTM(data_path + \"11151521.p\",load=True,training=False)\n",
    "# test=pickle.load(open(data_path+\"semtest.p\",'rb'))\n",
    "# print ls.chkterr2(test)\n",
    "#Example\n",
    "sa=\"A truly wise man\"\n",
    "sb=\"He is smart\"\n",
    "print ls.predict_similarity(sa,sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n",
      "/home/M2015eliu/.pyenv/versions/anaconda2-4.1.1/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec\n",
      "Pre-training\n",
      "Training\n",
      "(1.8461788, 0.35209775, 0.32704752901402195)\n",
      "Epoch 0\n",
      "Epoch  0 Update  40 Cost  0.116226390004\n",
      "Epoch  0 Update  80 Cost  0.0852465182543\n",
      "Epoch  0 Update  120 Cost  0.0872608870268\n",
      "Epoch  0 Update  160 Cost  0.0690286532044\n",
      "Epoch  0 Update  200 Cost  0.0691980719566\n",
      "Epoch  0 Update  240 Cost  0.0783870965242\n",
      "Epoch  0 Update  280 Cost  0.0977067500353\n",
      "Epoch  0 Update  320 Cost  0.0810800641775\n",
      "epoch took: 11.9861781597\n",
      "(0.85288763, 0.52564019, 0.50763920274659335)\n",
      "Epoch 1\n",
      "Epoch  1 Update  360 Cost  0.0607440061867\n",
      "Epoch  1 Update  400 Cost  0.0547560527921\n",
      "Epoch  1 Update  440 Cost  0.0733433663845\n",
      "Epoch  1 Update  480 Cost  0.057502578944\n",
      "Epoch  1 Update  520 Cost  0.0793796926737\n",
      "Epoch  1 Update  560 Cost  0.0554818436503\n",
      "Epoch  1 Update  600 Cost  0.0672504454851\n",
      "Epoch  1 Update  640 Cost  0.075273245573\n",
      "Epoch  1 Update  680 Cost  0.0670549198985\n",
      "epoch took: 11.8489580154\n",
      "(0.77519423, 0.5536117, 0.53214595795644026)\n",
      "Epoch 2\n",
      "Epoch  2 Update  720 Cost  0.0688732042909\n",
      "Epoch  2 Update  760 Cost  0.0520150214434\n",
      "Epoch  2 Update  800 Cost  0.032168596983\n",
      "Epoch  2 Update  840 Cost  0.0683300942183\n",
      "Epoch  2 Update  880 Cost  0.0600932314992\n",
      "Epoch  2 Update  920 Cost  0.0804345607758\n",
      "Epoch  2 Update  960 Cost  0.0461690612137\n",
      "Epoch  2 Update  1000 Cost  0.0533003732562\n",
      "Epoch  2 Update  1040 Cost  0.051845356822\n",
      "epoch took: 11.8362920284\n",
      "Pre-training done\n",
      "expanding the training data\n",
      "13376\n",
      "Training\n",
      "(0.67866594, 0.59754092, 0.57410547564708059)\n",
      "Epoch 0\n",
      "Epoch  0 Update  40 Cost  0.0350658074021\n",
      "Epoch  0 Update  80 Cost  0.034572403878\n",
      "Epoch  0 Update  120 Cost  0.0205028224736\n",
      "Epoch  0 Update  160 Cost  0.0366997569799\n",
      "Epoch  0 Update  200 Cost  0.0237171072513\n",
      "Epoch  0 Update  240 Cost  0.0300669632852\n",
      "Epoch  0 Update  280 Cost  0.0217619128525\n",
      "Epoch  0 Update  320 Cost  0.0295890159905\n",
      "epoch took: 6.18785810471\n",
      "(0.49833649, 0.71718943, 0.66594482082948692)\n",
      "Epoch 1\n",
      "Epoch  1 Update  360 Cost  0.0222179107368\n",
      "Epoch  1 Update  400 Cost  0.0232183523476\n",
      "Epoch  1 Update  440 Cost  0.0348091237247\n",
      "Epoch  1 Update  480 Cost  0.0244043879211\n",
      "Epoch  1 Update  520 Cost  0.0168917048723\n",
      "Epoch  1 Update  560 Cost  0.0229261983186\n",
      "Epoch  1 Update  600 Cost  0.0306548718363\n",
      "Epoch  1 Update  640 Cost  0.0245994701982\n",
      "epoch took: 6.14830803871\n",
      "(0.45855287, 0.74628401, 0.68971585637769739)\n",
      "Epoch 2\n",
      "Epoch  2 Update  680 Cost  0.0135421073064\n",
      "Epoch  2 Update  720 Cost  0.0188943799585\n",
      "Epoch  2 Update  760 Cost  0.0159520376474\n",
      "Epoch  2 Update  800 Cost  0.0225890763104\n",
      "Epoch  2 Update  840 Cost  0.0154151581228\n",
      "Epoch  2 Update  880 Cost  0.0147498175502\n",
      "Epoch  2 Update  920 Cost  0.0209079869092\n",
      "Epoch  2 Update  960 Cost  0.0206574462354\n",
      "epoch took: 6.15492796898\n",
      "(0.43909636, 0.75983518, 0.70160551611936417)\n",
      "Epoch 3\n",
      "Epoch  3 Update  1000 Cost  0.0160671919584\n",
      "Epoch  3 Update  1040 Cost  0.0162996407598\n",
      "Epoch  3 Update  1080 Cost  0.0181303136051\n",
      "Epoch  3 Update  1120 Cost  0.0282230898738\n",
      "Epoch  3 Update  1160 Cost  0.0174690876156\n",
      "Epoch  3 Update  1200 Cost  0.0185569096357\n",
      "Epoch  3 Update  1240 Cost  0.0139520755038\n",
      "Epoch  3 Update  1280 Cost  0.0144201274961\n",
      "epoch took: 6.14826798439\n",
      "(0.43660426, 0.7639662, 0.70612954336924239)\n",
      "Epoch 4\n",
      "Epoch  4 Update  1320 Cost  0.0211192779243\n",
      "Epoch  4 Update  1360 Cost  0.0244027636945\n",
      "Epoch  4 Update  1400 Cost  0.0113476328552\n",
      "Epoch  4 Update  1440 Cost  0.0152887422591\n",
      "Epoch  4 Update  1480 Cost  0.0128700658679\n",
      "Epoch  4 Update  1520 Cost  0.0170108489692\n",
      "Epoch  4 Update  1560 Cost  0.0118428207934\n",
      "Epoch  4 Update  1600 Cost  0.0232944488525\n",
      "epoch took: 6.18027305603\n",
      "(0.42094988, 0.77145427, 0.70864057226218657)\n",
      "Epoch 5\n",
      "Epoch  5 Update  1640 Cost  0.00857318006456\n",
      "Epoch  5 Update  1680 Cost  0.0118038542569\n",
      "Epoch  5 Update  1720 Cost  0.0126481214538\n",
      "Epoch  5 Update  1760 Cost  0.0167664214969\n",
      "Epoch  5 Update  1800 Cost  0.0233282856643\n",
      "Epoch  5 Update  1840 Cost  0.0156184071675\n",
      "Epoch  5 Update  1880 Cost  0.0247704349458\n",
      "Epoch  5 Update  1920 Cost  0.0188437048346\n",
      "epoch took: 6.17696213722\n",
      "(0.40849677, 0.78087205, 0.72041031726413163)\n",
      "Epoch 6\n",
      "Epoch  6 Update  1960 Cost  0.0126991663128\n",
      "Epoch  6 Update  2000 Cost  0.012365036644\n",
      "Epoch  6 Update  2040 Cost  0.0178914070129\n",
      "Epoch  6 Update  2080 Cost  0.009526245296\n",
      "Epoch  6 Update  2120 Cost  0.0164450407028\n",
      "Epoch  6 Update  2160 Cost  0.0164203513414\n",
      "Epoch  6 Update  2200 Cost  0.0106370253488\n",
      "Epoch  6 Update  2240 Cost  0.0196244884282\n",
      "epoch took: 6.21478891373\n",
      "(0.41192043, 0.77866471, 0.71364703792788686)\n",
      "Epoch 7\n",
      "Epoch  7 Update  2280 Cost  0.0216840002686\n",
      "Epoch  7 Update  2320 Cost  0.0198360141367\n",
      "Epoch  7 Update  2360 Cost  0.01050205715\n",
      "Epoch  7 Update  2400 Cost  0.0144297918305\n",
      "Epoch  7 Update  2440 Cost  0.0118769370019\n",
      "Epoch  7 Update  2480 Cost  0.0218507014215\n",
      "Epoch  7 Update  2520 Cost  0.0142132779583\n",
      "Epoch  7 Update  2560 Cost  0.0163671560585\n",
      "epoch took: 6.19026780128\n",
      "(0.40895581, 0.78165424, 0.72057801138692257)\n",
      "Epoch 8\n",
      "Epoch  8 Update  2600 Cost  0.0137034729123\n",
      "Epoch  8 Update  2640 Cost  0.0113548394293\n",
      "Epoch  8 Update  2680 Cost  0.0153300110251\n",
      "Epoch  8 Update  2720 Cost  0.0119220372289\n",
      "Epoch  8 Update  2760 Cost  0.0134959220886\n",
      "Epoch  8 Update  2800 Cost  0.0137664023787\n",
      "Epoch  8 Update  2840 Cost  0.013581299223\n",
      "Epoch  8 Update  2880 Cost  0.0177903734148\n",
      "epoch took: 6.20209503174\n",
      "(0.40193096, 0.78519076, 0.72330164077312142)\n",
      "Epoch 9\n",
      "Epoch  9 Update  2920 Cost  0.00998757220805\n",
      "Epoch  9 Update  2960 Cost  0.0185560174286\n",
      "Epoch  9 Update  3000 Cost  0.0172320567071\n",
      "Epoch  9 Update  3040 Cost  0.0160165354609\n",
      "Epoch  9 Update  3080 Cost  0.0114344153553\n",
      "Epoch  9 Update  3120 Cost  0.0132529241964\n",
      "Epoch  9 Update  3160 Cost  0.0126041704789\n",
      "Epoch  9 Update  3200 Cost  0.0117049366236\n",
      "Epoch  9 Update  3240 Cost  0.020793473348\n",
      "epoch took: 6.20275402069\n",
      "(0.3977783, 0.7878077, 0.72518274844162334)\n",
      "[ 0.48674893]\n",
      "saving the model...\n"
     ]
    }
   ],
   "source": [
    "from lstm import *\n",
    "data_path = \"./data/\"\n",
    "training=True # Set to false to load weights\n",
    "Syn_aug=True # it False faster but does slightly worse on Test dataset\n",
    "sls=LSTM(data_path+\"11151554.p\",load=False,training=True)\n",
    "train=pickle.load(open(data_path+\"stsallrmf.p\",\"rb\"))#[:-8]\n",
    "if training==True:\n",
    "    print \"Pre-training\"\n",
    "    sls.train_lstm(train,3) #66\n",
    "    print \"Pre-training done\"\n",
    "    train=pickle.load(open(data_path+\"semtrain.p\",'rb'))\n",
    "    if Syn_aug==True:\n",
    "        print \"expanding the training data\"\n",
    "        train=expand(train)\n",
    "        sls.train_lstm(train,10) # 340\n",
    "    else:\n",
    "        sls.train_lstm(train,10) # 330\n",
    "\n",
    "print sls.chkterr2(test)\n",
    "#Example\n",
    "sa=\"A truly wise man\"\n",
    "sb=\"He is smart\"\n",
    "print sls.predict_similarity(sa,sb)\n",
    "\n",
    "sls.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n",
      "/home/M2015eliu/.pyenv/versions/anaconda2-4.1.1/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec\n",
      "[ 0.48674893]\n"
     ]
    }
   ],
   "source": [
    "from lstm import *\n",
    "data_path = \"./data/\"\n",
    "ls=LSTM(data_path + \"11151554.p\",load=True,training=False)\n",
    "# test=pickle.load(open(data_path+\"semtest.p\",'rb'))\n",
    "# print ls.chkterr2(test)\n",
    "#Example\n",
    "sa=\"A truly wise man\"\n",
    "sb=\"He is smart\"\n",
    "print ls.predict_similarity(sa,sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3977783, 0.7878077, 0.72518274844162334)\n"
     ]
    }
   ],
   "source": [
    "test=pickle.load(open(data_path+\"semtest.p\",'rb'))\n",
    "print ls.chkterr2(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
