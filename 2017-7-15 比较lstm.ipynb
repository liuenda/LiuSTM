{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 25 epoch 10 dim_lstm 200 dim_Dense 400 100\n",
      "dropout_rate 0.0\n",
      "Activation function: ['relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "('Reading english Data:', 5000)\n",
      "('Reading english Data:', 5000)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:382: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "keras_title.py:383: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "keras_title.py:387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "keras_title.py:388: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 6 position: [1016, 1395, 3123, 3385, 3988, 4322]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:468: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 25, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 25, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 200)           320800      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 200)           320800      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 400)           0           lstm_1[0][0]                     \n",
      "                                                                   lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 400)           160400      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 400)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           40100       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             101         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 842,201\n",
      "Trainable params: 842,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 11s - loss: 0.5715 - val_loss: 0.5255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:117: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Subtensor..., inputs=[/main_inp...)`\n",
      "  model_1 = Model(input=[input_1, input_2], output=[lstm_out_1, lstm_out_2])\n",
      "keras_title.py:160: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 27\n",
      "TOP5 146\n",
      "TOP10 228\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 11s - loss: 0.2989 - val_loss: 0.4641\n",
      "TOP1 40\n",
      "TOP5 214\n",
      "TOP10 340\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 11s - loss: 0.1935 - val_loss: 0.4165\n",
      "TOP1 54\n",
      "TOP5 243\n",
      "TOP10 389\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 11s - loss: 0.1312 - val_loss: 0.3791\n",
      "TOP1 49\n",
      "TOP5 266\n",
      "TOP10 406\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 11s - loss: 0.0894 - val_loss: 0.3995\n",
      "TOP1 63\n",
      "TOP5 273\n",
      "TOP10 405\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 11s - loss: 0.0630 - val_loss: 0.3866\n",
      "TOP1 59\n",
      "TOP5 274\n",
      "TOP10 419\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 9s - loss: 0.0440 - val_loss: 0.3926\n",
      "TOP1 55\n",
      "TOP5 292\n",
      "TOP10 445\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 9s - loss: 0.0352 - val_loss: 0.4098\n",
      "TOP1 53\n",
      "TOP5 283\n",
      "TOP10 436\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 9s - loss: 0.0262 - val_loss: 0.4022\n",
      "TOP1 57\n",
      "TOP5 290\n",
      "TOP10 442\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 9s - loss: 0.0251 - val_loss: 0.4101\n",
      "TOP1 46\n",
      "TOP5 270\n",
      "TOP10 409\n",
      "TOP1 46\n",
      "TOP5 270\n",
      "TOP10 409\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 25 epoch 10 dim_lstm 200 dim_Dense 400 100\n",
      "dropout_rate 0.0\n",
      "Activation function: ['relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "('Reading english Data:', 5000)\n",
      "('Reading english Data:', 5000)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:382: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "keras_title.py:383: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "keras_title.py:387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "keras_title.py:388: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 2 position: [3690, 3960]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:468: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 25, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 25, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                   (None, 200)           320800      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                   (None, 200)           320800      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)     (None, 400)           0           lstm_25[0][0]                    \n",
      "                                                                   lstm_26[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 400)           160400      concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)             (None, 400)           0           dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 100)           40100       dropout_25[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)             (None, 100)           0           dense_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             101         dropout_26[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 842,201\n",
      "Trainable params: 842,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 10s - loss: 0.5793 - val_loss: 0.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:117: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Subtensor..., inputs=[/main_inp...)`\n",
      "  model_1 = Model(input=[input_1, input_2], output=[lstm_out_1, lstm_out_2])\n",
      "keras_title.py:160: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 19\n",
      "TOP5 128\n",
      "TOP10 217\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 9s - loss: 0.3313 - val_loss: 0.4513\n",
      "TOP1 28\n",
      "TOP5 187\n",
      "TOP10 301\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 9s - loss: 0.2011 - val_loss: 0.4378\n",
      "TOP1 45\n",
      "TOP5 222\n",
      "TOP10 362\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 9s - loss: 0.1312 - val_loss: 0.4345\n",
      "TOP1 42\n",
      "TOP5 260\n",
      "TOP10 384\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 9s - loss: 0.0961 - val_loss: 0.4778\n",
      "TOP1 50\n",
      "TOP5 246\n",
      "TOP10 380\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 9s - loss: 0.0608 - val_loss: 0.4577\n",
      "TOP1 53\n",
      "TOP5 252\n",
      "TOP10 404\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 9s - loss: 0.0438 - val_loss: 0.4167\n",
      "TOP1 58\n",
      "TOP5 252\n",
      "TOP10 404\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 9s - loss: 0.0316 - val_loss: 0.4704\n",
      "TOP1 56\n",
      "TOP5 255\n",
      "TOP10 410\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 9s - loss: 0.0307 - val_loss: 0.4498\n",
      "TOP1 58\n",
      "TOP5 238\n",
      "TOP10 380\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 9s - loss: 0.0290 - val_loss: 0.4952\n",
      "TOP1 39\n",
      "TOP5 206\n",
      "TOP10 335\n",
      "TOP1 39\n",
      "TOP5 206\n",
      "TOP10 335\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense 400 200\n",
      "dropout_rate 0.0\n",
      "Activation function: ['relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "('Reading english Data:', 5000)\n",
      "('Reading english Data:', 5000)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:382: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "keras_title.py:383: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "keras_title.py:387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "keras_title.py:388: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 6 position: [1166, 3400, 4127, 4269, 4278, 4281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:468: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_49 (LSTM)                   (None, 200)           320800      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_50 (LSTM)                   (None, 200)           320800      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)     (None, 400)           0           lstm_49[0][0]                    \n",
      "                                                                   lstm_50[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_49 (Dense)                 (None, 400)           160400      concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)             (None, 400)           0           dense_49[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_50 (Dense)                 (None, 200)           80200       dropout_49[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)             (None, 200)           0           dense_50[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             201         dropout_50[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 882,401\n",
      "Trainable params: 882,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 8s - loss: 0.5809 - val_loss: 0.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:117: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Subtensor..., inputs=[/main_inp...)`\n",
      "  model_1 = Model(input=[input_1, input_2], output=[lstm_out_1, lstm_out_2])\n",
      "keras_title.py:160: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 29\n",
      "TOP5 148\n",
      "TOP10 249\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 8s - loss: 0.3177 - val_loss: 0.4658\n",
      "TOP1 39\n",
      "TOP5 196\n",
      "TOP10 308\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 8s - loss: 0.1973 - val_loss: 0.3809\n",
      "TOP1 49\n",
      "TOP5 221\n",
      "TOP10 363\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 8s - loss: 0.1307 - val_loss: 0.4029\n",
      "TOP1 46\n",
      "TOP5 240\n",
      "TOP10 378\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 8s - loss: 0.0850 - val_loss: 0.4116\n",
      "TOP1 54\n",
      "TOP5 261\n",
      "TOP10 398\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 8s - loss: 0.0564 - val_loss: 0.3853\n",
      "TOP1 61\n",
      "TOP5 275\n",
      "TOP10 449\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 8s - loss: 0.0435 - val_loss: 0.3562\n",
      "TOP1 66\n",
      "TOP5 270\n",
      "TOP10 423\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 8s - loss: 0.0330 - val_loss: 0.4005\n",
      "TOP1 50\n",
      "TOP5 258\n",
      "TOP10 403\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 8s - loss: 0.0229 - val_loss: 0.4039\n",
      "TOP1 48\n",
      "TOP5 242\n",
      "TOP10 384\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 8s - loss: 0.0216 - val_loss: 0.4271\n",
      "TOP1 32\n",
      "TOP5 234\n",
      "TOP10 401\n",
      "TOP1 32\n",
      "TOP5 234\n",
      "TOP10 401\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense 400 200\n",
      "dropout_rate 0.2\n",
      "Activation function: ['relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "('Reading english Data:', 5000)\n",
      "('Reading english Data:', 5000)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:382: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "keras_title.py:383: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "keras_title.py:387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "keras_title.py:388: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 3 position: [2720, 3359, 3364]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:468: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_73 (LSTM)                   (None, 200)           320800      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_74 (LSTM)                   (None, 200)           320800      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)     (None, 400)           0           lstm_73[0][0]                    \n",
      "                                                                   lstm_74[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_73 (Dense)                 (None, 400)           160400      concatenate_37[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)             (None, 400)           0           dense_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_74 (Dense)                 (None, 200)           80200       dropout_73[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)             (None, 200)           0           dense_74[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             201         dropout_74[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 882,401\n",
      "Trainable params: 882,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 9s - loss: 0.6419 - val_loss: 0.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:117: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Subtensor..., inputs=[/main_inp...)`\n",
      "  model_1 = Model(input=[input_1, input_2], output=[lstm_out_1, lstm_out_2])\n",
      "keras_title.py:160: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 33\n",
      "TOP5 123\n",
      "TOP10 216\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 9s - loss: 0.3648 - val_loss: 0.4829\n",
      "TOP1 31\n",
      "TOP5 154\n",
      "TOP10 258\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 9s - loss: 0.2511 - val_loss: 0.4148\n",
      "TOP1 40\n",
      "TOP5 210\n",
      "TOP10 343\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 9s - loss: 0.1824 - val_loss: 0.3939\n",
      "TOP1 49\n",
      "TOP5 230\n",
      "TOP10 378\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 9s - loss: 0.1370 - val_loss: 0.3971\n",
      "TOP1 55\n",
      "TOP5 225\n",
      "TOP10 368\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 9s - loss: 0.0991 - val_loss: 0.4122\n",
      "TOP1 56\n",
      "TOP5 236\n",
      "TOP10 384\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 9s - loss: 0.0736 - val_loss: 0.4524\n",
      "TOP1 62\n",
      "TOP5 247\n",
      "TOP10 379\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 8s - loss: 0.0631 - val_loss: 0.3861\n",
      "TOP1 57\n",
      "TOP5 280\n",
      "TOP10 414\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 8s - loss: 0.0561 - val_loss: 0.4294\n",
      "TOP1 52\n",
      "TOP5 262\n",
      "TOP10 394\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 8s - loss: 0.0496 - val_loss: 0.5159\n",
      "TOP1 52\n",
      "TOP5 243\n",
      "TOP10 394\n",
      "TOP1 52\n",
      "TOP5 243\n",
      "TOP10 394\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense 100 2\n",
      "dropout_rate 0.0\n",
      "Activation function: ['relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "('Reading english Data:', 5000)\n",
      "('Reading english Data:', 5000)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:384: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_en'] = df_pairs_sample['en_article'].apply(doc2vec_en)\n",
      "keras_title.py:385: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['word2vec_jp'] = df_pairs_sample['jp_article'].apply(doc2vec_jp)\n",
      "keras_title.py:389: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_en'] = df_pairs_sample['word2vec_en'].apply(padding)\n",
      "keras_title.py:390: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 5 position: [1001, 1034, 3397, 3678, 4933]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:470: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  model_lstm2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                    (None, 200)           320800      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                   (None, 200)           320800      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 400)           0           lstm_9[0][0]                     \n",
      "                                                                   lstm_10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 100)           40100       concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 100)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 2)             202         dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 2)             0           dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             3           dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 681,905\n",
      "Trainable params: 681,905\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 8s - loss: 1.0002 - val_loss: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:119: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Subtensor..., inputs=[/main_inp...)`\n",
      "  model_1 = Model(input=[input_1, input_2], output=[lstm_out_1, lstm_out_2])\n",
      "keras_title.py:162: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2 = Model(input=[input_1, input_2], output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 0\n",
      "TOP5 0\n",
      "TOP10 0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 8s - loss: 0.9510 - val_loss: 0.9314\n",
      "TOP1 0\n",
      "TOP5 0\n",
      "TOP10 0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 8s - loss: 0.8821 - val_loss: 0.9154\n",
      "TOP1 0\n",
      "TOP5 0\n",
      "TOP10 0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 8s - loss: 0.8433 - val_loss: 0.9366\n",
      "TOP1 0\n",
      "TOP5 0\n",
      "TOP10 0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 8s - loss: 0.8167 - val_loss: 0.8575\n",
      "TOP1 0\n",
      "TOP5 0\n",
      "TOP10 0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 8s - loss: 0.6471 - val_loss: 0.6735\n",
      "TOP1 0\n",
      "TOP5 0\n",
      "TOP10 5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 8s - loss: 0.4671 - val_loss: 0.6217\n",
      "TOP1 1\n",
      "TOP5 12\n",
      "TOP10 80\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 8s - loss: 0.3606 - val_loss: 0.5534\n",
      "TOP1 3\n",
      "TOP5 36\n",
      "TOP10 93\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 8s - loss: 0.2886 - val_loss: 0.5871\n",
      "TOP1 2\n",
      "TOP5 44\n",
      "TOP10 97\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 8s - loss: 0.2360 - val_loss: 0.5747\n",
      "TOP1 2\n",
      "TOP5 53\n",
      "TOP10 111\n",
      "TOP1 2\n",
      "TOP5 53\n",
      "TOP10 111\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense 400 100 50\n",
      "dropout_rate 0.0\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "('Reading english Data:', 5000)\n",
      "('Reading english Data:', 5000)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:390: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_pairs_sample['padding_jp'] = df_pairs_sample['word2vec_jp'].apply(padding)\n",
      "keras_title.py:391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "keras_title.py:395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Generate training data (similarity = 1)\n",
      "keras_title.py:396: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_en_1 = np.stack(df_pairs_sample[\"padding_en\"].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 6 position: [1000, 2602, 3405, 3884, 4298, 4418]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:476: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_57 (LSTM)                   (None, 200)           320800      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_58 (LSTM)                   (None, 200)           320800      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)     (None, 400)           0           lstm_57[0][0]                    \n",
      "                                                                   lstm_58[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_69 (Dense)                 (None, 400)           160400      concatenate_29[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)             (None, 400)           0           dense_69[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_70 (Dense)                 (None, 100)           40100       dropout_69[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)             (None, 100)           0           dense_70[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_71 (Dense)                 (None, 50)            5050        dropout_70[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)             (None, 50)            0           dense_71[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             51          dropout_71[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 847,201\n",
      "Trainable params: 847,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 8s - loss: 0.5833 - val_loss: 0.5203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:120: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Subtensor..., inputs=[/main_inp...)`\n",
      "  \n",
      "keras_title.py:166: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2.compile(optimizer='adam', loss=loss_function)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 16\n",
      "TOP5 88\n",
      "TOP10 158\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 8s - loss: 0.2987 - val_loss: 0.4488\n",
      "TOP1 34\n",
      "TOP5 166\n",
      "TOP10 296\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 8s - loss: 0.2024 - val_loss: 0.5162\n",
      "TOP1 21\n",
      "TOP5 138\n",
      "TOP10 251\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 8s - loss: 0.1461 - val_loss: 0.4118\n",
      "TOP1 28\n",
      "TOP5 163\n",
      "TOP10 292\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 8s - loss: 0.1364 - val_loss: 0.4260\n",
      "TOP1 31\n",
      "TOP5 181\n",
      "TOP10 294\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 8s - loss: 0.0953 - val_loss: 0.4928\n",
      "TOP1 16\n",
      "TOP5 143\n",
      "TOP10 253\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 8s - loss: 0.0764 - val_loss: 0.4624\n",
      "TOP1 11\n",
      "TOP5 81\n",
      "TOP10 178\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 8s - loss: 0.0651 - val_loss: 0.4738\n",
      "TOP1 19\n",
      "TOP5 155\n",
      "TOP10 275\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 8s - loss: 0.0531 - val_loss: 0.5637\n",
      "TOP1 17\n",
      "TOP5 136\n",
      "TOP10 236\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 8s - loss: 0.0541 - val_loss: 0.5060\n",
      "TOP1 16\n",
      "TOP5 131\n",
      "TOP10 247\n",
      "TOP1 16\n",
      "TOP5 131\n",
      "TOP10 247\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense\n",
      "200\n",
      "dropout_rate 0.0\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "('Reading english Data:', 5000)\n",
      "('Reading english Data:', 5000)\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "keras_title.py:392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "keras_title.py:396: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_en_1 = np.stack(df_pairs_sample[\"padding_en\"].values)\n",
      "keras_title.py:397: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_jp_1 = np.stack(df_pairs_sample[\"padding_jp\"].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 3 position: [1814, 2868, 3391]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:477: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  # Show the structure of the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_81 (LSTM)                   (None, 200)           320800      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_82 (LSTM)                   (None, 200)           320800      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)     (None, 400)           0           lstm_81[0][0]                    \n",
      "                                                                   lstm_82[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_105 (Dense)                (None, 200)           80200       concatenate_41[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)            (None, 200)           0           dense_105[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             201         dropout_105[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 722,001\n",
      "Trainable params: 722,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 8s - loss: 0.5995 - val_loss: 0.5041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:121: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Subtensor..., inputs=[/main_inp...)`\n",
      "  # Compile the model\n",
      "keras_title.py:167: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 25\n",
      "TOP5 170\n",
      "TOP10 263\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 8s - loss: 0.3457 - val_loss: 0.4407\n",
      "TOP1 32\n",
      "TOP5 227\n",
      "TOP10 339\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 8s - loss: 0.2577 - val_loss: 0.4061\n",
      "TOP1 52\n",
      "TOP5 256\n",
      "TOP10 415\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 8s - loss: 0.1966 - val_loss: 0.4320\n",
      "TOP1 66\n",
      "TOP5 263\n",
      "TOP10 405\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 8s - loss: 0.1492 - val_loss: 0.4260\n",
      "TOP1 55\n",
      "TOP5 265\n",
      "TOP10 398\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 8s - loss: 0.1196 - val_loss: 0.4543\n",
      "TOP1 60\n",
      "TOP5 273\n",
      "TOP10 430\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 8s - loss: 0.0895 - val_loss: 0.4247\n",
      "TOP1 58\n",
      "TOP5 301\n",
      "TOP10 460\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 8s - loss: 0.0746 - val_loss: 0.4359\n",
      "TOP1 62\n",
      "TOP5 285\n",
      "TOP10 419\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 8s - loss: 0.0583 - val_loss: 0.4395\n",
      "TOP1 62\n",
      "TOP5 274\n",
      "TOP10 428\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 8s - loss: 0.0474 - val_loss: 0.4555\n",
      "TOP1 56\n",
      "TOP5 294\n",
      "TOP10 426\n",
      "TOP1 56\n",
      "TOP5 294\n",
      "TOP10 426\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense\n",
      "200\n",
      "dropout_rate 0.0\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "Reading english Data: 5000\n",
      "Reading english Data: 5000\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "keras_title.py:392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "keras_title.py:396: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_en_1 = np.stack(df_pairs_sample[\"padding_en\"].values)\n",
      "keras_title.py:397: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_jp_1 = np.stack(df_pairs_sample[\"padding_jp\"].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 5 position: [240, 987, 1784, 3379, 3684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:477: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  # Show the structure of the model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_105 (LSTM)                  (None, 200)           320800      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_106 (LSTM)                  (None, 200)           320800      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)     (None, 400)           0           lstm_105[0][0]                   \n",
      "                                                                   lstm_106[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_117 (Dense)                (None, 200)           80200       concatenate_53[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)            (None, 200)           0           dense_117[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             201         dropout_117[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 722,001\n",
      "Trainable params: 722,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 8s - loss: 0.1562 - val_loss: 0.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:121: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Subtensor..., inputs=[/main_inp...)`\n",
      "  # Compile the model\n",
      "keras_title.py:167: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 31\n",
      "TOP5 104\n",
      "TOP10 211\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 8s - loss: 0.0853 - val_loss: 0.1241\n",
      "TOP1 37\n",
      "TOP5 211\n",
      "TOP10 330\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 8s - loss: 0.0596 - val_loss: 0.1119\n",
      "TOP1 66\n",
      "TOP5 276\n",
      "TOP10 428\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 8s - loss: 0.0451 - val_loss: 0.1174\n",
      "TOP1 57\n",
      "TOP5 273\n",
      "TOP10 410\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 8s - loss: 0.0342 - val_loss: 0.1196\n",
      "TOP1 64\n",
      "TOP5 266\n",
      "TOP10 401\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 8s - loss: 0.0273 - val_loss: 0.1127\n",
      "TOP1 72\n",
      "TOP5 279\n",
      "TOP10 407\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 8s - loss: 0.0224 - val_loss: 0.1167\n",
      "TOP1 67\n",
      "TOP5 264\n",
      "TOP10 441\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 8s - loss: 0.0188 - val_loss: 0.1172\n",
      "TOP1 56\n",
      "TOP5 290\n",
      "TOP10 441\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 8s - loss: 0.0151 - val_loss: 0.1135\n",
      "TOP1 81\n",
      "TOP5 288\n",
      "TOP10 428\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 8s - loss: 0.0123 - val_loss: 0.1074\n",
      "TOP1 73\n",
      "TOP5 308\n",
      "TOP10 438\n",
      "TOP1 73\n",
      "TOP5 308\n",
      "TOP10 438\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense\n",
      "200\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "Reading english Data: 5000\n",
      "Reading english Data: 5000\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:400: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_en_0 = np.array(features_en_1)\n",
      "keras_title.py:401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  np.random.shuffle((features_en_0))\n",
      "keras_title.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  print \"C value =\", c.sum(), \"position:\", np.where(c== True)[0].tolist()\n",
      "keras_title.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 9 position: [895, 917, 1006, 1040, 2405, 3400, 4086, 4415, 4521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:490: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  X2_test_1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional)  (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional)  (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)     (None, 800)           0           bidirectional_7[0][0]            \n",
      "                                                                   bidirectional_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_131 (Dense)                (None, 200)           160200      concatenate_67[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)            (None, 200)           0           dense_131[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             201         dropout_131[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,443,601\n",
      "Trainable params: 1,443,601\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 16s - loss: 0.1688 - val_loss: 0.1397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:126: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
      "keras_title.py:176: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  # Set the weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 33\n",
      "TOP5 128\n",
      "TOP10 232\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 15s - loss: 0.0932 - val_loss: 0.1252\n",
      "TOP1 43\n",
      "TOP5 214\n",
      "TOP10 344\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 16s - loss: 0.0654 - val_loss: 0.1213\n",
      "TOP1 51\n",
      "TOP5 243\n",
      "TOP10 371\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 15s - loss: 0.0495 - val_loss: 0.1105\n",
      "TOP1 59\n",
      "TOP5 284\n",
      "TOP10 418\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 15s - loss: 0.0379 - val_loss: 0.1169\n",
      "TOP1 60\n",
      "TOP5 282\n",
      "TOP10 421\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 15s - loss: 0.0290 - val_loss: 0.1177\n",
      "TOP1 63\n",
      "TOP5 289\n",
      "TOP10 443\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 16s - loss: 0.0240 - val_loss: 0.1150\n",
      "TOP1 70\n",
      "TOP5 301\n",
      "TOP10 451\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 16s - loss: 0.0186 - val_loss: 0.1189\n",
      "TOP1 55\n",
      "TOP5 278\n",
      "TOP10 407\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 16s - loss: 0.0158 - val_loss: 0.1222\n",
      "TOP1 50\n",
      "TOP5 281\n",
      "TOP10 404\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 15s - loss: 0.0132 - val_loss: 0.1194\n",
      "TOP1 58\n",
      "TOP5 315\n",
      "TOP10 428\n",
      "TOP1 58\n",
      "TOP5 315\n",
      "TOP10 428\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense\n",
      "200\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "Reading english Data: 5000\n",
      "Reading english Data: 5000\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:400: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_en_0 = np.array(features_en_1)\n",
      "keras_title.py:401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  np.random.shuffle((features_en_0))\n",
      "keras_title.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  print \"C value =\", c.sum(), \"position:\", np.where(c== True)[0].tolist()\n",
      "keras_title.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 8 position: [998, 1032, 1472, 2784, 3075, 4145, 4261, 4729]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:490: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  X2_test_1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_31 (Bidirectional) (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_32 (Bidirectional) (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)     (None, 800)           0           bidirectional_31[0][0]           \n",
      "                                                                   bidirectional_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_143 (Dense)                (None, 200)           160200      concatenate_79[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)            (None, 200)           0           dense_143[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             201         dropout_143[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,443,601\n",
      "Trainable params: 1,443,601\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 15s - loss: 0.6317 - val_loss: 0.5577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:126: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
      "keras_title.py:176: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  # Set the weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 21\n",
      "TOP5 116\n",
      "TOP10 178\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 15s - loss: 0.3857 - val_loss: 0.4828\n",
      "TOP1 39\n",
      "TOP5 173\n",
      "TOP10 277\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 15s - loss: 0.2835 - val_loss: 0.4676\n",
      "TOP1 31\n",
      "TOP5 205\n",
      "TOP10 305\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 15s - loss: 0.2216 - val_loss: 0.4522\n",
      "TOP1 49\n",
      "TOP5 214\n",
      "TOP10 373\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 15s - loss: 0.1732 - val_loss: 0.4369\n",
      "TOP1 55\n",
      "TOP5 259\n",
      "TOP10 393\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 15s - loss: 0.1386 - val_loss: 0.4482\n",
      "TOP1 60\n",
      "TOP5 263\n",
      "TOP10 409\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 15s - loss: 0.1117 - val_loss: 0.4545\n",
      "TOP1 59\n",
      "TOP5 265\n",
      "TOP10 436\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 15s - loss: 0.0854 - val_loss: 0.4687\n",
      "TOP1 66\n",
      "TOP5 275\n",
      "TOP10 419\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 15s - loss: 0.0676 - val_loss: 0.4800\n",
      "TOP1 57\n",
      "TOP5 250\n",
      "TOP10 407\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 16s - loss: 0.0578 - val_loss: 0.4765\n",
      "TOP1 56\n",
      "TOP5 266\n",
      "TOP10 397\n",
      "TOP1 56\n",
      "TOP5 266\n",
      "TOP10 397\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense\n",
      "400\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "Reading english Data: 5000\n",
      "Reading english Data: 5000\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:400: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_en_0 = np.array(features_en_1)\n",
      "keras_title.py:401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  np.random.shuffle((features_en_0))\n",
      "keras_title.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  print \"C value =\", c.sum(), \"position:\", np.where(c== True)[0].tolist()\n",
      "keras_title.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 8 position: [1034, 2038, 2235, 3361, 4063, 4064, 4323, 4324]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:490: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  X2_test_1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_55 (Bidirectional) (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_56 (Bidirectional) (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)     (None, 800)           0           bidirectional_55[0][0]           \n",
      "                                                                   bidirectional_56[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_155 (Dense)                (None, 400)           320400      concatenate_91[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)            (None, 400)           0           dense_155[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             401         dropout_155[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,604,001\n",
      "Trainable params: 1,604,001\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 15s - loss: 0.6102 - val_loss: 0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:126: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
      "keras_title.py:176: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  # Set the weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 15\n",
      "TOP5 97\n",
      "TOP10 193\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 15s - loss: 0.3683 - val_loss: 0.4668\n",
      "TOP1 32\n",
      "TOP5 177\n",
      "TOP10 277\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 16s - loss: 0.2735 - val_loss: 0.4474\n",
      "TOP1 46\n",
      "TOP5 226\n",
      "TOP10 366\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 16s - loss: 0.2105 - val_loss: 0.4471\n",
      "TOP1 48\n",
      "TOP5 245\n",
      "TOP10 389\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 15s - loss: 0.1661 - val_loss: 0.4370\n",
      "TOP1 42\n",
      "TOP5 248\n",
      "TOP10 393\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 16s - loss: 0.1325 - val_loss: 0.4362\n",
      "TOP1 69\n",
      "TOP5 291\n",
      "TOP10 429\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 15s - loss: 0.1009 - val_loss: 0.4726\n",
      "TOP1 47\n",
      "TOP5 278\n",
      "TOP10 403\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 15s - loss: 0.0853 - val_loss: 0.4782\n",
      "TOP1 61\n",
      "TOP5 289\n",
      "TOP10 419\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 16s - loss: 0.0675 - val_loss: 0.4438\n",
      "TOP1 49\n",
      "TOP5 284\n",
      "TOP10 429\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 16s - loss: 0.0532 - val_loss: 0.4536\n",
      "TOP1 56\n",
      "TOP5 285\n",
      "TOP10 430\n",
      "TOP1 56\n",
      "TOP5 285\n",
      "TOP10 430\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200 dim_Dense\n",
      "50\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "Reading english Data: 5000\n",
      "Reading english Data: 5000\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:400: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_en_0 = np.array(features_en_1)\n",
      "keras_title.py:401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  np.random.shuffle((features_en_0))\n",
      "keras_title.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  print \"C value =\", c.sum(), \"position:\", np.where(c== True)[0].tolist()\n",
      "keras_title.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 8 position: [1467, 1964, 2967, 3305, 3437, 4289, 4321, 4473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:490: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  X2_test_1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_79 (Bidirectional) (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_80 (Bidirectional) (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)    (None, 800)           0           bidirectional_79[0][0]           \n",
      "                                                                   bidirectional_80[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_167 (Dense)                (None, 50)            40050       concatenate_103[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)            (None, 50)            0           dense_167[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             51          dropout_167[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,323,301\n",
      "Trainable params: 1,323,301\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 16s - loss: 0.6442 - val_loss: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:126: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
      "keras_title.py:176: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  # Set the weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 18\n",
      "TOP5 90\n",
      "TOP10 149\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 15s - loss: 0.4096 - val_loss: 0.4864\n",
      "TOP1 25\n",
      "TOP5 150\n",
      "TOP10 229\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 15s - loss: 0.3255 - val_loss: 0.4862\n",
      "TOP1 39\n",
      "TOP5 193\n",
      "TOP10 287\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 15s - loss: 0.2525 - val_loss: 0.4789\n",
      "TOP1 44\n",
      "TOP5 190\n",
      "TOP10 314\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 15s - loss: 0.2021 - val_loss: 0.4413\n",
      "TOP1 49\n",
      "TOP5 220\n",
      "TOP10 327\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 15s - loss: 0.1604 - val_loss: 0.4747\n",
      "TOP1 42\n",
      "TOP5 212\n",
      "TOP10 338\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 16s - loss: 0.1316 - val_loss: 0.4990\n",
      "TOP1 43\n",
      "TOP5 210\n",
      "TOP10 326\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 16s - loss: 0.1040 - val_loss: 0.5378\n",
      "TOP1 42\n",
      "TOP5 198\n",
      "TOP10 329\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 15s - loss: 0.0828 - val_loss: 0.5426\n",
      "TOP1 46\n",
      "TOP5 204\n",
      "TOP10 312\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 16s - loss: 0.0690 - val_loss: 0.5692\n",
      "TOP1 46\n",
      "TOP5 207\n",
      "TOP10 325\n",
      "TOP1 46\n",
      "TOP5 207\n",
      "TOP10 325\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 30 epoch 10 dim_lstm 200\n",
      "dim_Dense 600\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: -1\n",
      "loss_function: mse\n",
      "------------------------------\n",
      "Reading english Data: 5000\n",
      "Reading english Data: 5000\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    4995\n",
      "True        5\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:400: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  features_en_0 = np.array(features_en_1)\n",
      "keras_title.py:401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  np.random.shuffle((features_en_0))\n",
      "keras_title.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  print \"C value =\", c.sum(), \"position:\", np.where(c== True)[0].tolist()\n",
      "keras_title.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 6 position: [381, 399, 998, 1009, 2224, 4312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:490: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  X2_test_1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_103 (Bidirectional (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_104 (Bidirectional (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)    (None, 800)           0           bidirectional_103[0][0]          \n",
      "                                                                   bidirectional_104[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_179 (Dense)                (None, 600)           480600      concatenate_115[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)            (None, 600)           0           dense_179[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             601         dropout_179[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,764,401\n",
      "Trainable params: 1,764,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 23s - loss: 0.5860 - val_loss: 0.5060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:126: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
      "keras_title.py:176: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  # Set the weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 23\n",
      "TOP5 154\n",
      "TOP10 249\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 23s - loss: 0.3513 - val_loss: 0.4845\n",
      "TOP1 41\n",
      "TOP5 191\n",
      "TOP10 300\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 23s - loss: 0.2618 - val_loss: 0.4195\n",
      "TOP1 49\n",
      "TOP5 252\n",
      "TOP10 407\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 23s - loss: 0.1988 - val_loss: 0.4380\n",
      "TOP1 53\n",
      "TOP5 236\n",
      "TOP10 391\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 23s - loss: 0.1539 - val_loss: 0.4070\n",
      "TOP1 57\n",
      "TOP5 264\n",
      "TOP10 411\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 23s - loss: 0.1228 - val_loss: 0.4035\n",
      "TOP1 61\n",
      "TOP5 266\n",
      "TOP10 416\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 23s - loss: 0.1007 - val_loss: 0.4350\n",
      "TOP1 54\n",
      "TOP5 242\n",
      "TOP10 388\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 23s - loss: 0.0789 - val_loss: 0.4085\n",
      "TOP1 60\n",
      "TOP5 282\n",
      "TOP10 443\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 23s - loss: 0.0671 - val_loss: 0.4060\n",
      "TOP1 60\n",
      "TOP5 301\n",
      "TOP10 469\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 23s - loss: 0.0528 - val_loss: 0.4508\n",
      "TOP1 65\n",
      "TOP5 277\n",
      "TOP10 435\n",
      "TOP1 65\n",
      "TOP5 277\n",
      "TOP10 435\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 30 epoch 10 dim_lstm 200\n",
      "dim_Dense 600\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "start: 0 end:\n",
      "------------------------------\n",
      "Reading english Data: 59999\n",
      "Reading english Data: 59999\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    59987\n",
      "True        12\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # check the duplicated amount\n",
      "keras_title.py:404: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  c = np.all(features_en_1 == features_en_0, axis=(1,2))\n",
      "keras_title.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_1 = np.concatenate((features_en_1, features_en_0), axis = 0)\n",
      "keras_title.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_2 = np.concatenate((features_jp_1, features_jp_1), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 4 position: [1011, 1572, 3377, 4371]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:493: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  saved_model.append(deepcopy(model_lstm2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_127 (Bidirectional (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_128 (Bidirectional (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)    (None, 800)           0           bidirectional_127[0][0]          \n",
      "                                                                   bidirectional_128[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_191 (Dense)                (None, 600)           480600      concatenate_127[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_191 (Dropout)            (None, 600)           0           dense_191[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             601         dropout_191[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,764,401\n",
      "Trainable params: 1,764,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 22s - loss: 0.1582 - val_loss: 0.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:129: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # print model_1.summary()\n",
      "keras_title.py:179: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2.layers[7].set_weights(dlmodel.layers[9].get_weights())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 36\n",
      "TOP5 166\n",
      "TOP10 271\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 23s - loss: 0.0829 - val_loss: 0.1153\n",
      "TOP1 69\n",
      "TOP5 250\n",
      "TOP10 406\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 23s - loss: 0.0584 - val_loss: 0.1152\n",
      "TOP1 66\n",
      "TOP5 296\n",
      "TOP10 447\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 23s - loss: 0.0457 - val_loss: 0.1105\n",
      "TOP1 74\n",
      "TOP5 291\n",
      "TOP10 442\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 23s - loss: 0.0346 - val_loss: 0.1063\n",
      "TOP1 65\n",
      "TOP5 287\n",
      "TOP10 426\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 23s - loss: 0.0279 - val_loss: 0.1086\n",
      "TOP1 74\n",
      "TOP5 295\n",
      "TOP10 442\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 23s - loss: 0.0228 - val_loss: 0.1041\n",
      "TOP1 79\n",
      "TOP5 303\n",
      "TOP10 468\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 23s - loss: 0.0192 - val_loss: 0.1161\n",
      "TOP1 59\n",
      "TOP5 291\n",
      "TOP10 438\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 23s - loss: 0.0160 - val_loss: 0.1114\n",
      "TOP1 73\n",
      "TOP5 311\n",
      "TOP10 467\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 23s - loss: 0.0137 - val_loss: 0.1104\n",
      "TOP1 71\n",
      "TOP5 331\n",
      "TOP10 458\n",
      "TOP1 71\n",
      "TOP5 331\n",
      "TOP10 458\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 20 epoch 10 dim_lstm 200\n",
      "dim_Dense 600\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "start: 0 end:\n",
      "------------------------------\n",
      "Reading english Data: 59999\n",
      "Reading english Data: 59999\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    59987\n",
      "True        12\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # check the duplicated amount\n",
      "keras_title.py:404: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  c = np.all(features_en_1 == features_en_0, axis=(1,2))\n",
      "keras_title.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_1 = np.concatenate((features_en_1, features_en_0), axis = 0)\n",
      "keras_title.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_2 = np.concatenate((features_jp_1, features_jp_1), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 11 position: [534, 547, 1001, 1018, 2601, 2949, 3378, 3384, 3812, 4283, 4292]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:493: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  saved_model.append(deepcopy(model_lstm2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 20, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_151 (Bidirectional (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_152 (Bidirectional (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)    (None, 800)           0           bidirectional_151[0][0]          \n",
      "                                                                   bidirectional_152[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_203 (Dense)                (None, 600)           480600      concatenate_139[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_203 (Dropout)            (None, 600)           0           dense_203[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             601         dropout_203[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,764,401\n",
      "Trainable params: 1,764,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 15s - loss: 0.1583 - val_loss: 0.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:129: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # print model_1.summary()\n",
      "keras_title.py:179: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2.layers[7].set_weights(dlmodel.layers[9].get_weights())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 29\n",
      "TOP5 135\n",
      "TOP10 254\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 16s - loss: 0.0882 - val_loss: 0.1209\n",
      "TOP1 46\n",
      "TOP5 188\n",
      "TOP10 317\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 16s - loss: 0.0624 - val_loss: 0.1229\n",
      "TOP1 55\n",
      "TOP5 235\n",
      "TOP10 392\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 16s - loss: 0.0479 - val_loss: 0.1052\n",
      "TOP1 56\n",
      "TOP5 254\n",
      "TOP10 401\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 16s - loss: 0.0366 - val_loss: 0.1163\n",
      "TOP1 45\n",
      "TOP5 267\n",
      "TOP10 418\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 16s - loss: 0.0295 - val_loss: 0.1120\n",
      "TOP1 58\n",
      "TOP5 279\n",
      "TOP10 424\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 16s - loss: 0.0234 - val_loss: 0.1144\n",
      "TOP1 67\n",
      "TOP5 290\n",
      "TOP10 435\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 16s - loss: 0.0181 - val_loss: 0.1134\n",
      "TOP1 69\n",
      "TOP5 307\n",
      "TOP10 460\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 16s - loss: 0.0151 - val_loss: 0.1101\n",
      "TOP1 74\n",
      "TOP5 291\n",
      "TOP10 445\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 16s - loss: 0.0129 - val_loss: 0.1149\n",
      "TOP1 69\n",
      "TOP5 285\n",
      "TOP10 446\n",
      "TOP1 69\n",
      "TOP5 285\n",
      "TOP10 446\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 30 epoch 10 dim_lstm 200\n",
      "dim_Dense 600\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "start: 0 end:\n",
      "------------------------------\n",
      "Reading english Data: 59999\n",
      "Reading english Data: 59999\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    59987\n",
      "True        12\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # check the duplicated amount\n",
      "keras_title.py:404: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  c = np.all(features_en_1 == features_en_0, axis=(1,2))\n",
      "keras_title.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_1 = np.concatenate((features_en_1, features_en_0), axis = 0)\n",
      "keras_title.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_2 = np.concatenate((features_jp_1, features_jp_1), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 3 position: [3193, 4260, 4326]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:493: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  saved_model.append(deepcopy(model_lstm2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_175 (Bidirectional (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_176 (Bidirectional (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)    (None, 800)           0           bidirectional_175[0][0]          \n",
      "                                                                   bidirectional_176[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_215 (Dense)                (None, 600)           480600      concatenate_151[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_215 (Dropout)            (None, 600)           0           dense_215[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             601         dropout_215[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,764,401\n",
      "Trainable params: 1,764,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 23s - loss: 0.1641 - val_loss: 0.1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:129: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # print model_1.summary()\n",
      "keras_title.py:179: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2.layers[7].set_weights(dlmodel.layers[9].get_weights())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 26\n",
      "TOP5 154\n",
      "TOP10 254\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 23s - loss: 0.0850 - val_loss: 0.1153\n",
      "TOP1 57\n",
      "TOP5 266\n",
      "TOP10 393\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 23s - loss: 0.0607 - val_loss: 0.1116\n",
      "TOP1 58\n",
      "TOP5 259\n",
      "TOP10 399\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 22s - loss: 0.0478 - val_loss: 0.1122\n",
      "TOP1 52\n",
      "TOP5 300\n",
      "TOP10 429\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 23s - loss: 0.0359 - val_loss: 0.1093\n",
      "TOP1 66\n",
      "TOP5 310\n",
      "TOP10 454\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 23s - loss: 0.0300 - val_loss: 0.1208\n",
      "TOP1 73\n",
      "TOP5 326\n",
      "TOP10 468\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 23s - loss: 0.0228 - val_loss: 0.1090\n",
      "TOP1 66\n",
      "TOP5 309\n",
      "TOP10 473\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 23s - loss: 0.0192 - val_loss: 0.1267\n",
      "TOP1 72\n",
      "TOP5 311\n",
      "TOP10 463\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 23s - loss: 0.0153 - val_loss: 0.1169\n",
      "TOP1 61\n",
      "TOP5 334\n",
      "TOP10 475\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 23s - loss: 0.0120 - val_loss: 0.1196\n",
      "TOP1 60\n",
      "TOP5 328\n",
      "TOP10 488\n",
      "TOP1 60\n",
      "TOP5 328\n",
      "TOP10 488\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 30 epoch 10 dim_lstm 200\n",
      "dim_Dense 600\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "start: 0 end:\n",
      "------------------------------\n",
      "Reading english Data: 59999\n",
      "Reading english Data: 59999\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    59987\n",
      "True        12\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # check the duplicated amount\n",
      "keras_title.py:404: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  c = np.all(features_en_1 == features_en_0, axis=(1,2))\n",
      "keras_title.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_1 = np.concatenate((features_en_1, features_en_0), axis = 0)\n",
      "keras_title.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_2 = np.concatenate((features_jp_1, features_jp_1), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 2 position: [4316, 4503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:493: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  saved_model.append(deepcopy(model_lstm2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_199 (Bidirectional (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_200 (Bidirectional (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)    (None, 800)           0           bidirectional_199[0][0]          \n",
      "                                                                   bidirectional_200[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_227 (Dense)                (None, 600)           480600      concatenate_163[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_227 (Dropout)            (None, 600)           0           dense_227[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             601         dropout_227[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,764,401\n",
      "Trainable params: 1,764,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 22s - loss: 0.1619 - val_loss: 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:129: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # print model_1.summary()\n",
      "keras_title.py:179: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2.layers[7].set_weights(dlmodel.layers[9].get_weights())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 31\n",
      "TOP5 136\n",
      "TOP10 252\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 23s - loss: 0.0874 - val_loss: 0.1156\n",
      "TOP1 42\n",
      "TOP5 221\n",
      "TOP10 380\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 22s - loss: 0.0628 - val_loss: 0.1133\n",
      "TOP1 41\n",
      "TOP5 233\n",
      "TOP10 386\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 23s - loss: 0.0488 - val_loss: 0.1154\n",
      "TOP1 67\n",
      "TOP5 306\n",
      "TOP10 454\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 23s - loss: 0.0393 - val_loss: 0.1123\n",
      "TOP1 69\n",
      "TOP5 286\n",
      "TOP10 417\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 23s - loss: 0.0301 - val_loss: 0.1102\n",
      "TOP1 62\n",
      "TOP5 302\n",
      "TOP10 435\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 23s - loss: 0.0250 - val_loss: 0.1108\n",
      "TOP1 58\n",
      "TOP5 299\n",
      "TOP10 438\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 23s - loss: 0.0197 - val_loss: 0.1135\n",
      "TOP1 63\n",
      "TOP5 307\n",
      "TOP10 457\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 23s - loss: 0.0163 - val_loss: 0.1102\n",
      "TOP1 64\n",
      "TOP5 306\n",
      "TOP10 442\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 23s - loss: 0.0139 - val_loss: 0.1102\n",
      "TOP1 76\n",
      "TOP5 310\n",
      "TOP10 456\n",
      "TOP1 76\n",
      "TOP5 310\n",
      "TOP10 456\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 30 epoch 10 dim_lstm 200\n",
      "dim_Dense 800\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "start: 0 end:\n",
      "------------------------------\n",
      "Reading english Data: 59999\n",
      "Reading english Data: 59999\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    59987\n",
      "True        12\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # check the duplicated amount\n",
      "keras_title.py:404: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  c = np.all(features_en_1 == features_en_0, axis=(1,2))\n",
      "keras_title.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_1 = np.concatenate((features_en_1, features_en_0), axis = 0)\n",
      "keras_title.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_2 = np.concatenate((features_jp_1, features_jp_1), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 6 position: [343, 1028, 3372, 4292, 4319, 4634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:493: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  saved_model.append(deepcopy(model_lstm2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_223 (Bidirectional (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_224 (Bidirectional (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)    (None, 800)           0           bidirectional_223[0][0]          \n",
      "                                                                   bidirectional_224[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_239 (Dense)                (None, 800)           640800      concatenate_175[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_239 (Dropout)            (None, 800)           0           dense_239[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             801         dropout_239[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,924,801\n",
      "Trainable params: 1,924,801\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 22s - loss: 0.1593 - val_loss: 0.1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:129: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # print model_1.summary()\n",
      "keras_title.py:179: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2.layers[7].set_weights(dlmodel.layers[9].get_weights())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 35\n",
      "TOP5 160\n",
      "TOP10 295\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 22s - loss: 0.0883 - val_loss: 0.1173\n",
      "TOP1 44\n",
      "TOP5 220\n",
      "TOP10 365\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 22s - loss: 0.0640 - val_loss: 0.1015\n",
      "TOP1 59\n",
      "TOP5 258\n",
      "TOP10 413\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 23s - loss: 0.0482 - val_loss: 0.1052\n",
      "TOP1 61\n",
      "TOP5 292\n",
      "TOP10 428\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 23s - loss: 0.0376 - val_loss: 0.1011\n",
      "TOP1 77\n",
      "TOP5 327\n",
      "TOP10 468\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 23s - loss: 0.0303 - val_loss: 0.0996\n",
      "TOP1 60\n",
      "TOP5 343\n",
      "TOP10 491\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 23s - loss: 0.0230 - val_loss: 0.1092\n",
      "TOP1 74\n",
      "TOP5 311\n",
      "TOP10 492\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 23s - loss: 0.0193 - val_loss: 0.1078\n",
      "TOP1 74\n",
      "TOP5 332\n",
      "TOP10 502\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 23s - loss: 0.0155 - val_loss: 0.1126\n",
      "TOP1 79\n",
      "TOP5 328\n",
      "TOP10 476\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 23s - loss: 0.0137 - val_loss: 0.1067\n",
      "TOP1 74\n",
      "TOP5 308\n",
      "TOP10 471\n",
      "TOP1 74\n",
      "TOP5 308\n",
      "TOP10 471\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 30 epoch 10 dim_lstm 200\n",
      "dim_Dense 1000\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "start: 0 end:\n",
      "------------------------------\n",
      "Reading english Data: 59999\n",
      "Reading english Data: 59999\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    59987\n",
      "True        12\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # check the duplicated amount\n",
      "keras_title.py:404: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  c = np.all(features_en_1 == features_en_0, axis=(1,2))\n",
      "keras_title.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_1 = np.concatenate((features_en_1, features_en_0), axis = 0)\n",
      "keras_title.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_2 = np.concatenate((features_jp_1, features_jp_1), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 7 position: [690, 988, 1604, 3431, 3954, 4295, 4875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:493: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  saved_model.append(deepcopy(model_lstm2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_247 (Bidirectional (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_248 (Bidirectional (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)    (None, 800)           0           bidirectional_247[0][0]          \n",
      "                                                                   bidirectional_248[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_251 (Dense)                (None, 1000)          801000      concatenate_187[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_251 (Dropout)            (None, 1000)          0           dense_251[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             1001        dropout_251[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 2,085,201\n",
      "Trainable params: 2,085,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 23s - loss: 0.1579 - val_loss: 0.1369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:129: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # print model_1.summary()\n",
      "keras_title.py:179: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2.layers[7].set_weights(dlmodel.layers[9].get_weights())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 31\n",
      "TOP5 155\n",
      "TOP10 255\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 23s - loss: 0.0868 - val_loss: 0.1233\n",
      "TOP1 39\n",
      "TOP5 229\n",
      "TOP10 357\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 23s - loss: 0.0625 - val_loss: 0.1176\n",
      "TOP1 55\n",
      "TOP5 248\n",
      "TOP10 401\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 23s - loss: 0.0499 - val_loss: 0.1151\n",
      "TOP1 48\n",
      "TOP5 264\n",
      "TOP10 423\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 23s - loss: 0.0406 - val_loss: 0.1083\n",
      "TOP1 52\n",
      "TOP5 268\n",
      "TOP10 424\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 23s - loss: 0.0324 - val_loss: 0.1104\n",
      "TOP1 68\n",
      "TOP5 294\n",
      "TOP10 457\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 23s - loss: 0.0258 - val_loss: 0.1199\n",
      "TOP1 71\n",
      "TOP5 288\n",
      "TOP10 449\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 23s - loss: 0.0209 - val_loss: 0.1163\n",
      "TOP1 70\n",
      "TOP5 283\n",
      "TOP10 429\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 23s - loss: 0.0170 - val_loss: 0.1151\n",
      "TOP1 62\n",
      "TOP5 287\n",
      "TOP10 443\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 23s - loss: 0.0150 - val_loss: 0.1110\n",
      "TOP1 69\n",
      "TOP5 300\n",
      "TOP10 449\n",
      "TOP1 69\n",
      "TOP5 300\n",
      "TOP10 449\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 30 epoch 10 dim_lstm 200\n",
      "dim_Dense 800\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "start: 0 end:\n",
      "------------------------------\n",
      "Reading english Data: 59999\n",
      "Reading english Data: 59999\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    59987\n",
      "True        12\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:403: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # check the duplicated amount\n",
      "keras_title.py:404: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  c = np.all(features_en_1 == features_en_0, axis=(1,2))\n",
      "keras_title.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_1 = np.concatenate((features_en_1, features_en_0), axis = 0)\n",
      "keras_title.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  X_2 = np.concatenate((features_jp_1, features_jp_1), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 7 position: [239, 991, 1965, 3369, 4192, 4267, 4308]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:493: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  saved_model.append(deepcopy(model_lstm2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_271 (Bidirectional (None, 400)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_272 (Bidirectional (None, 400)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_199 (Concatenate)    (None, 800)           0           bidirectional_271[0][0]          \n",
      "                                                                   bidirectional_272[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_263 (Dense)                (None, 800)           640800      concatenate_199[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_263 (Dropout)            (None, 800)           0           dense_263[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             801         dropout_263[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,924,801\n",
      "Trainable params: 1,924,801\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 22s - loss: 0.1569 - val_loss: 0.1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:129: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Join.0, J..., inputs=[/main_inp...)`\n",
      "  # print model_1.summary()\n",
      "keras_title.py:179: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  model_2.layers[7].set_weights(dlmodel.layers[9].get_weights())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 32\n",
      "TOP5 167\n",
      "TOP10 274\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 22s - loss: 0.0859 - val_loss: 0.1265\n",
      "TOP1 40\n",
      "TOP5 188\n",
      "TOP10 332\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 23s - loss: 0.0598 - val_loss: 0.1099\n",
      "TOP1 46\n",
      "TOP5 252\n",
      "TOP10 391\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 23s - loss: 0.0443 - val_loss: 0.1146\n",
      "TOP1 55\n",
      "TOP5 296\n",
      "TOP10 441\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 23s - loss: 0.0355 - val_loss: 0.1095\n",
      "TOP1 54\n",
      "TOP5 302\n",
      "TOP10 459\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 23s - loss: 0.0270 - val_loss: 0.1156\n",
      "TOP1 59\n",
      "TOP5 289\n",
      "TOP10 420\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 23s - loss: 0.0227 - val_loss: 0.1165\n",
      "TOP1 65\n",
      "TOP5 304\n",
      "TOP10 439\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 23s - loss: 0.0180 - val_loss: 0.1192\n",
      "TOP1 63\n",
      "TOP5 313\n",
      "TOP10 466\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 23s - loss: 0.0147 - val_loss: 0.1194\n",
      "TOP1 72\n",
      "TOP5 307\n",
      "TOP10 454\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 23s - loss: 0.0126 - val_loss: 0.1173\n",
      "TOP1 71\n",
      "TOP5 313\n",
      "TOP10 458\n",
      "TOP1 71\n",
      "TOP5 313\n",
      "TOP10 458\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 30 epoch 10 dim_lstm 200\n",
      "dim_Dense 800\n",
      "dropout_rate 0.0 , LSTM type: bi-lstm sum\n",
      "Activation function: ['relu', 'relu', 'relu']\n",
      "bias of y: 0\n",
      "loss_function: mse\n",
      "start: 0 end:\n",
      "------------------------------\n",
      "Reading english Data: 59999\n",
      "Reading english Data: 59999\n",
      "Merging the English and Japanes news dataframe...\n",
      "Drop the null line...\n",
      "False    59987\n",
      "True        12\n",
      "Name: en_article, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:406: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "keras_title.py:407: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Prepare the final training and test data\n",
      "keras_title.py:411: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  y = np.concatenate((np.ones(len(features_en_1)), np.zeros(len(features_en_0))+bias_y), axis = 0)\n",
      "keras_title.py:412: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # y = np.concatenate((np.ones(len(features_en_1)), np.zeros(len(features_en_0))), axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value = 1 position: [3369]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:496: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/main_inp...)`\n",
      "  print \"TOP1\", (pd.Series(rank_results_test) <= 1).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input_1 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_input_2 (InputLayer)        (None, 30, 200)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_301 (Bidirectional (None, 200)           641600      main_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_302 (Bidirectional (None, 200)           641600      main_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_214 (Concatenate)    (None, 400)           0           bidirectional_301[0][0]          \n",
      "                                                                   bidirectional_302[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_278 (Dense)                (None, 800)           320800      concatenate_214[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_278 (Dropout)            (None, 800)           0           dense_278[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 1)             801         dropout_278[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,604,801\n",
      "Trainable params: 1,604,801\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 22s - loss: 0.1612 - val_loss: 0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_title.py:130: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[Elemwise{..., inputs=[/main_inp...)`\n",
      "  \n",
      "keras_title.py:182: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{a..., inputs=[/lstm1, /...)`\n",
      "  projection2 = v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP1 24\n",
      "TOP5 152\n",
      "TOP10 269\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 22s - loss: 0.0839 - val_loss: 0.1092\n",
      "TOP1 45\n",
      "TOP5 229\n",
      "TOP10 349\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 23s - loss: 0.0597 - val_loss: 0.1162\n",
      "TOP1 52\n",
      "TOP5 257\n",
      "TOP10 397\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 4/4\n",
      "8000/8000 [==============================] - 23s - loss: 0.0485 - val_loss: 0.1093\n",
      "TOP1 71\n",
      "TOP5 280\n",
      "TOP10 437\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 22s - loss: 0.0372 - val_loss: 0.1072\n",
      "TOP1 57\n",
      "TOP5 294\n",
      "TOP10 463\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 6/6\n",
      "8000/8000 [==============================] - 23s - loss: 0.0296 - val_loss: 0.1091\n",
      "TOP1 80\n",
      "TOP5 305\n",
      "TOP10 471\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 7/7\n",
      "8000/8000 [==============================] - 23s - loss: 0.0240 - val_loss: 0.1076\n",
      "TOP1 70\n",
      "TOP5 309\n",
      "TOP10 468\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 8/8\n",
      "8000/8000 [==============================] - 23s - loss: 0.0198 - val_loss: 0.1203\n",
      "TOP1 67\n",
      "TOP5 300\n",
      "TOP10 452\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 9/9\n",
      "8000/8000 [==============================] - 23s - loss: 0.0162 - val_loss: 0.1028\n",
      "TOP1 75\n",
      "TOP5 335\n",
      "TOP10 476\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 23s - loss: 0.0130 - val_loss: 0.1043\n",
      "TOP1 78\n",
      "TOP5 317\n",
      "TOP10 480\n",
      "TOP1 78\n",
      "TOP5 317\n",
      "TOP10 480\n"
     ]
    }
   ],
   "source": [
    "run keras_title.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAHBCAYAAAA/yFyLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7fa89c9890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 2.0)\n",
    "# matplotlib.rcParams['figure.figsize'] = (10, 7)\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 7)\n",
    "plt.plot(rank_results_test,'bo')\n",
    "plt.title('TOP Ranking for test documents (1-1000)')\n",
    "plt.xlabel('Document Number')\n",
    "plt.ylabel('The ranking of the real pair')\n",
    "# plt.ylim([1000,0])\n",
    "plt.ylim([532,0.5])\n",
    "plt.grid(True)\n",
    "plt.savefig('top-test.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAHBCAYAAAA/yFyLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8049685cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 2.0)\n",
    "# matplotlib.rcParams['figure.figsize'] = (10, 7)\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 7)\n",
    "plt.plot(rank_results_test,'bo')\n",
    "plt.title('TOP Ranking for test documents (1-1000)')\n",
    "plt.xlabel('Document Number')\n",
    "plt.ylabel('The ranking of the real pair')\n",
    "# plt.ylim([1000,0])\n",
    "plt.ylim([532,0.5])\n",
    "plt.grid(True)\n",
    "plt.savefig('top-test.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       43.336000\n",
       "std        97.073404\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%        11.500000\n",
       "75%        43.125000\n",
       "max       877.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rank_results_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f8053a85090>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "find_ranking_quick(X1_test_1, X2_test_1, model_lstm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
